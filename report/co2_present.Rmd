---
title: "Comparing Global $CO_{2}$ Emission Models from 1997 and Today"
short: "A comparative follow up report"
journal: "AER" # AER, AEJ, PP, JEL
month: "`r format(Sys.Date(), '%m')`"
year: "`r format(Sys.Date(), '%Y')`"
vol: 0
issue: 0
keywords:
  - Replication
  - Modern Science
author:
  - name: Carolyn Dunlap
  - name: Ayda Nayeb Nazar
  - name: Qian Qiao
  - name: Hector Rincon
acknowledgements: | 
  The authors would like to thank their instructors from MIDS 271.
abstract: | 
  In 1997, our team analyzed the 
  The year is 1997 and global attention is turning toward the consequences of human-actions in our environmental system. The IPCC has been in existence and studying these trends for more than ten years, and has released its second assessment report in 1995. In this report, the IPCC notes that the balance of the evidence suggests that human-actions play a role in the changing climate. Although, there is little political will to change this activity, neither have global progressive and conservative politicians broken into clear partisan camps. Here, we assess data from the Mona Loa observatory to describe and predict global $CO_{2}$ concentrations under several possible scenarios. What we find, when we run the analysis, is going to be grim. 
header-includes: 
  - '\usepackage{graphicx}'
  - '\usepackage{booktabs}'
output: rticles::aea_article
---

```{r setup, echo=FALSE}
## default to not show code, unless we ask for it.
knitr::opts_chunk$set(echo=FALSE)
options(digits = 3)
```

```{r load packages, echo = FALSE, message = FALSE}
library(tidyverse)
library(tsibble)
library(latex2exp)
library(patchwork)
library(lubridate)
library(feasts)
library(forecast)
library(sandwich)
library(lmtest)
theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```

# Introduction 

In this introduction, you can assume that your reader will have **just** read your 1997 report. In this introduction, **very** briefly pose the question that you are evaluating, and describe what (if anything) has changed in the data generating process between 1997 and the present.

# Measurement and Data 

## (3 points) Task 1b: Create a modern data pipeline for Mona Loa CO2 data.
The most current data is provided by the United States' National Oceanic and Atmospheric Administration, on a data page [[here](https://gml.noaa.gov/ccgg/trends/data.html)]. Gather the most recent weekly data from this page. (A group that is interested in even more data management might choose to work with the [hourly data](https://gml.noaa.gov/aftp/data/trace_gases/co2/in-situ/surface/mlo/co2_mlo_surface-insitu_1_ccgg_HourlyData.txt).)
Create a data pipeline that starts by reading from the appropriate URL, and ends by saving an object called `co2_present` that is a suitable time series object.

```{r Fetch data from NOAA, eval=F, echo=FALSE}
# change eval=T to run this for the first time, otherwise always load the (already saved) data
noaa_colnames <- c('year', 'month', 'day', 'decimal', 'ppm', 'n.days', 'lag.1Y', 'lag.10Y', 'delta.1800')
co2_present <- read_table('https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.txt', skip = 53, col_names = noaa_colnames, na="-999.99")
co2_present <- mutate(co2_present, date = as.Date(paste(year, month, day, sep="-"))) %>% mutate(week = yearweek(date, week_start=7)) # start week on Sunday
co2_present <- select(co2_present, -decimal, -delta.1800, -year, -month, -day)

# Create the tsibble
co2_present <- as_tsibble(co2_present, index=week)

# Save the data
save(co2_present, file='co2_data.RData')
```

```{r Load the data, eval=T, echo=FALSE}
load('co2_data.RData')
```

## Historical Trends in Atmospheric Carbon 

Conduct the same EDA on this data. Describe how the Keeling Curve evolved from 1997 to the present, noting where the series seems to be following similar trends to the series that you "evaluated in 1997" and where the series seems to be following different trends. This EDA can use the same, or very similar tools and views as you provided in your 1997 report.

Atmospheric carbon is plotted in \autoref{fig:carbon}, and shows some worrying trends. Just look at how wobbly that line is. How is it possible that we are not living in a simulation, when the lines that plots monthly average $CO_{2}$ looks like this? 

```{r present time series, echo = FALSE}
ts_co2_present <- tsibble::as_tsibble(co2_present)

#time plot
p1_plot <- ggplot(ts_co2_present, aes(x = date, y = ppm)) +
  geom_line(color = 'steelblue') +
  geom_vline(xintercept = as.Date("1997-01-01"), color = "red") +
  labs(
    title = "Figure 1", 
    subtitle = TeX(r'(Weekly Mean $CO_2$ at Mauna Loa 1974-2023)'),
    x = 'Month',
    y = TeX(r'($CO_2$ parts per million)')
  ) + 
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") + 
	theme(axis.text.x=element_text(angle=90, vjust=0.5))
p1_plot
```


```{r present histogram ACF PACF, echo = FALSE}
#histogram, ACF and PACF
p2_histogram <- ts_co2_present %>%
  ggplot(aes(x = ppm)) +
  geom_histogram() +
  labs(title = "Figure 2a", 
    subtitle=TeX(r'(Histogram of Weekly Mean $CO_2$)'),
        x = TeX(r'($CO_2$ parts per million)'))

p3_acf <- ts_co2_present %>%
  ACF(ppm) %>%
  autoplot() +
  labs(title = "Figure 2b", 
    subtitle=TeX(r'(ACF of Weekly Mean $CO_2$)'))

p4_pacf <- ts_co2_present %>%
  PACF(ppm) %>%
  autoplot() +
  labs(title = "Figure 2c", 
    subtitle=TeX(r'(PACF of Weekly Mean $CO_2$)'))

#arranging plots
(p2_histogram) /
  (p3_acf | p4_pacf)
```

\begin{figure}
  \includegraphics[width=.8\linewidth]{./figures/plot_1.pdf}
  \caption{An uncareful plot.\label{fig:carbon}}
  \begin{figurenotes}
    After giving a declarative statement about what is in the plot, it is useful to provide a very concise interpretation of what you see, or how you read the plot. It should be possible for a reader to \textit{almost} read your entire report from tables, figures, and estimated models.
  \end{figurenotes}
\end{figure} 


# Models and Forecasts 

Through our exploratory data analysis, we fond 

## Comparing 1997 Linear Models 

Descriptively compare realized atmospheric CO2 levels to those predicted by your forecast from a linear time model in 1997 (i.e. "Task 2a"). (You do not need to run any formal tests for this task.)

To begin, we fit a model of the form: 

\begin{equation}
\label{eq:one}
\text{CO}_{2} = \phi_{0} + \phi_{1} + \epsilon_{eit}
\end{equation} 

which, a student of the class will immediately realize is a nonsense model that is senseless. However, writing out the model form that you are going to estimate makes it very clear what you're assuming about the data generating process. It also allows you to reference what models your forecasts are being generated from. We will be expecting such a declaration in your reports. 

We estimate best fitting parameters on this model in the following way, 

```{r Load the fitted linear (quad) model}
load('1997_quad_seasonal_modelfit.RData') # loads a co2_quadratic_season var
```


```{r Compare against the realised values}
# 1. Forecast using the model until Dec 2022 (from 1997 = 25 years)
dec2022.forecast.quad.model <- fabletools::forecast(co2_quadratic_season, h="25 years")

# 2. Plot the forecast + realised values
dec2022.forecast.quad.model <- dec2022.forecast.quad.model %>% mutate(index.date = as.Date(index))
forecast.realised.plot <- ggplot() +
	geom_line(data=co2_present, aes(date, ppm, color="Realised")) +
	geom_line(data=dec2022.forecast.quad.model, aes(index.date, `.mean`, color="Forecast")) +
	scale_x_date(date_breaks="1 year", date_labels = "%Y") +
	scale_y_continuous(n.breaks=50) +
	theme(axis.text.x=element_text(angle=90, vjust=0.5)) +
	labs(title="Quadratic model forecast vs realised values 1997-2022", x=NULL, y="CO2 ppm") +
	scale_color_discrete(name = "Series")
forecast.realised.plot
```

## Comparing 1997 ARIMA Models 

```{r Load the ARIMA model}
co2_arima_fit <- readRDS('1997_arima_modelfit.rds')
```


```{r Compare against the realised values}
# 1. Forecast using the model until Dec 2022 (from 1997 = 25 years)
dec2022.forecast.arima.model <- fabletools::forecast(co2_arima_fit, h="25 years")

# 2. Plot the forecast + realised values
dec2022.forecast.arima.model <- dec2022.forecast.arima.model %>% mutate(index.date = as.Date(index))
arima.forecast.realised.plot <- ggplot() +
	geom_line(data=co2_present, aes(date, ppm, color="Realised")) +
	geom_line(data=dec2022.forecast.arima.model, aes(index.date, `.mean`, color="Forecast")) +
	scale_x_date(date_breaks="1 year", date_labels = "%Y") +
	theme(axis.text.x=element_text(angle=90, vjust=0.5)) +
	labs(title="ARIMA model forecast vs realised values 1997-2022", x=NULL, y="CO2 ppm") +
	scale_color_discrete(name = "Series")
arima.forecast.realised.plot
```

Descriptively compare realized atmospheric CO2 levels to those predicted by your forecast from the ARIMA model that you fitted in 1997 (i.e. "Task 3a"). Describe how the Keeling Curve evolved from 1997 to the present.

Sure we also fit some ARIMA models. And talk about them. 

## Evaluation of 1997 Forecasts 

In 1997 you made predictions about the first time that CO2 would cross 420 ppm. How close were your models to the truth?
After reflecting on your performance on this threshold-prediction task, continue to use the weekly data to generate a month-average series from 1997 to the present, and compare the overall forecasting performance of your models from Parts 2a and 3b over the entire period. (You should conduct formal tests for this task.)

```{r Produce the monthly series}
monthly.co2 <- co2_present %>%
	index_by(month = yearmonth(week)) %>%
	summarise(ppm = mean(ppm, na.rm=T)) %>%
	tidyr::fill(ppm, .direction = "down") %>%
	mutate(index.date = as.Date(month))
```

```{r Plot the monthly series against the forecast}
p1 <- ggplot() +
	geom_line(data=monthly.co2, aes(index.date, ppm, color="Realised")) +
	geom_line(data=dec2022.forecast.arima.model, aes(index.date, `.mean`, color="Forecast - ARIMA")) +
	geom_line(data=dec2022.forecast.quad.model, aes(index.date, `.mean`, color="Forecast - Quadratic")) +
	# geom_point(data=monthly.co2, aes(index.date, ppm, color="Realised")) +
	scale_x_date(date_breaks="1 year", date_labels = "%Y") +
	theme(axis.text.x=element_text(angle=90, vjust=0.5)) +
	labs(title="ARIMA model forecast vs quadratic model forecast vs realised values 1997-2022", x=NULL, y="CO2 ppm") +
	scale_color_discrete(name = "Series")
p1
```

```{r Change the names to match the forecast}
names(monthly.co2) <- c('index', 'value', 'index.date')
```


```{r Running the tests for comparison}
dec2022.forecast.arima.model %>% fabletools::accuracy(monthly.co2)
dec2022.forecast.quad.model %>% fabletools::accuracy(monthly.co2)
```


Because we have fitted a model, we can make predictions from that model. Our preferred model, named in \autoref{eq:one} is quite simple, and as you might notice, does not in fact match up with the model that we have fitted. However, from this model is is possible to reason about what the outcomes would be if the *input concept* were to be slightly ouside of the observed data range. In particular, if *input concept* were as high as $11$, then we would expect the *output concept* to be `r prediction_1[1,1]`, with a prediction interval that ranges from [`r prediction_1[1,2]`, `r prediction_1[1,3]`]

# Training New Models Based on Present Data

## (4 points) Task 5b: Train best models on present data
Seasonally adjust the weekly NOAA data, and split both seasonally-adjusted (SA) and non-seasonally-adjusted (NSA) series into training and test sets, using the last two years of observations as the test sets. For both SA and NSA series, fit ARIMA models using all appropriate steps. Measure and discuss how your models perform in-sample and (psuedo-) out-of-sample, comparing candidate models and explaining your choice. In addition, fit a polynomial time-trend model to the seasonally-adjusted series and compare its performance to that of your ARIMA model.

```{r Seasonally adjust data}
# There are missing values, so we have to fill in the blanks (fill with the previous week value)

co2_present <- co2_present %>% tidyr::fill(ppm, .direction = "down")
dcmp_add <- co2_present %>% model(stl=STL(ppm))
co2_present.components <- components(dcmp_add)
```

```{r Split train/test}
test.df <- filter(co2_present.components, year(week) >= 2020 & year(week) < 2023)
train.df <- filter(co2_present.components, year(week) < 2020)
```

```{r Seasonally adjusted data tests for stationarity}
train.diff.sa <- train.df %>% mutate(diff = tsibble::difference(season_adjust, lag=1))
PP.test(train.diff.sa$diff[-1])
adf.test(train.diff.sa$diff[-1], alternative = "stationary")
```

```{r Non-seasonally adjusted data tests for stationarity}
train.diff.nsa <- train.df %>% mutate(diff = tsibble::difference(ppm, lag=1))
PP.test(train.diff.nsa$diff[-1])
adf.test(train.diff.nsa$diff[-1], alternative = "stationary")
```

```{r ARIMA models}
train.df.ts <- select(train.df, week, ppm)
# autofit.arima.aic <- train.df.ts %>% model(auto=ARIMA(ppm ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="aic", stepwise=F, greedy=F))
# autofit.arima.bic <- train.df.ts %>% model(auto=ARIMA(ppm ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="bic", stepwise=F, greedy=F))
autofit.arima.aic <- readRDS('autofit.arima.aic.nsa.rds')
autofit.arima.bic <- readRDS('autofit.arima.bic.nsa.rds')
autofit.arima.aic %>% report()
autofit.arima.bic %>% report()

train.df.ts.sa <- select(train.df, week, season_adjust)
# autofit.arima.aic.sa <- train.df.ts.sa %>% model(auto=ARIMA(season_adjust ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="aic", stepwise=F, greedy=F))
# autofit.arima.bic.sa <- train.df.ts.sa %>% model(auto=ARIMA(season_adjust ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="bic", stepwise=F, greedy=F))
# saveRDS(autofit.arima.aic.sa, file="autofit.arima.aic.sa.Rds")
# saveRDS(autofit.arima.bic.sa, file="autofit.arima.bic.sa.Rds")

autofit.arima.aic.sa <- readRDS('autofit.arima.aic.sa.Rds')
autofit.arima.bic.sa <- readRDS('autofit.arima.bic.sa.Rds')

autofit.arima.aic.sa %>% report()
autofit.arima.bic.sa %>% report()
```

### Evaluating accuracy


```{r In-sample}
bind_cols(data.frame(
	model=c('ARIMA(1,0,4)(1,1,0)[52] (NSA data)', 'ARIMA(0,1,2)(1,0,0)[52] (SA data)', 'ARIMA(1,0,2)(1,1,0)[52] (NSA data)', 'ARIMA(0,1,2)(1,0,0)[52] (SA data)'),
	IC=c('AIC', 'AIC', 'BIC', 'BIC')
	),
bind_rows(
	fabletools::accuracy(autofit.arima.aic),
	fabletools::accuracy(autofit.arima.aic.sa),
	fabletools::accuracy(autofit.arima.bic),
	fabletools::accuracy(autofit.arima.bic.sa),
))
```


```{r Out of sample NSA}
# Using the ARIMA(1,0,2)(1,1,0) (chosen by AIC)
nsa.fc <- fabletools::forecast(autofit.arima.bic,h="2 years")
attr(autofit.arima.bic$auto[[1]]$fit$tsp$range, 'week_start') <- 7
nd <- tsibble(week=yearweek(seq(ymd('2019-12-29'), ymd('2023-01-01'), by ='1 week'), week_start = 7))
nd <- tsibble::fill_gaps(nd)
attr(nd$week, "week_start") <- 7
nd <- as_tsibble(nd)
# nsa.fc <- fabletools::forecast(autofit.arima.bic, new_data=nd)
nsa.fc <- fabletools::forecast(autofit.arima.bic, h="2 years")
nsa.fc %>% fabletools::accuracy(select(test.df, week, ppm))
```

```{r Out of sample SA}
```

# How Bad Could It Get?

## (3 points) Task Part 6b: How bad could it get?
With the non-seasonally adjusted data series, generate predictions for when atmospheric CO2 is expected to be at 420 ppm and 500 ppm levels for the first and final times (consider prediction intervals as well as point estimates in your answer). Generate a prediction for atmospheric CO2 levels in the year 2122. How confident are you that these will be accurate predictions?

# Conclusions 

What to conclude is unclear. 


