---
title: "Comparing Global $CO_{2}$ Emission Models from 1997 and Today"
short: "A comparative follow up report"
journal: "AER" # AER, AEJ, PP, JEL
month: "`r format(Sys.Date(), '%m')`"
year: "`r format(Sys.Date(), '%Y')`"
vol: 0
issue: 0
keywords:
  - Replication
  - Modern Science
author:
  - name: Carolyn Dunlap
  - name: Ayda Nayeb Nazar
  - name: Qian Qiao
  - name: Hector Rincon
acknowledgements: | 
  The authors would like to thank their instructors from MIDS 271.
abstract: | 
  In 1997, our team analyzed $CO_{2}$ concentration avaerage monthly trends from 1959 to 1997. Our work culminated in a report that discussed multiple linear and ARIMA models of these concentration data and attempted to forecast $CO_{2}$ trends into the future, as far out as 2100. Given that we now have 25 more years of data, and at a highly weekly resolution, this report aims to revisit and evaluate our 1997 models. Using weekly average $CO_{2}$ concentration levels taking from the Mauna Loa observatory, we also analyze our data to fit new models and generate updated forcasts for potential $CO_{2}$ concentrations as far out as 100 years into the future.

header-includes: 
  - '\usepackage{graphicx}'
  - '\usepackage{booktabs}'
output: rticles::aea_article
---

```{r setup, echo=FALSE}
## default to not show code, unless we ask for it.
knitr::opts_chunk$set(echo=FALSE)
options(digits = 3)
```

```{r load packages, echo = FALSE, message = FALSE}
library(tidyverse)
library(tsibble)
library(latex2exp)
library(patchwork)
library(lubridate)
library(feasts)
library(forecast)
library(sandwich)
library(lmtest)
theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)
```

# Introduction 

In this report, we are continuing to evaluate atmospheric $CO_{2}$ trends (commonly referred to as the Keeling Curve), generating models and forecasts to help understand how we might expect atmospheric $CO_{2}$ levels to change in the future. Specifically, we are re-evaluating our best performing linear and ARIMA models from our 1997 report on $CO_{2}$ concentrations, using more recently generating weekly average $CO_{2}$ data up through the end of 2022. This report continues to use the $CO_{2}$ concentration data collected by the Mauna Loa observatory, with the key exception that we have weekly average $CO_{2}$ concentration data, compared to the monthly average concentration data used in 1997. Depending on the purposes of our analyses, we will either keep the weekly granularity or regenerate monthly averages as necessary. In addition to evaluating our 1997 models and forecasts, we will also use more recent data to generate new models and forecasts for $CO_{2}$ concentrations.

# Measurement and Data 

The data that we are using from this report was accessed via the United States' National Oceanic and Atmospheric Administration website, where they house continually updated weekly $CO_{2}$ concentration data collected from the Mauna Loa observatory. This data was collected in a similar manner to the data in 1997 with a few key exceptions. The first key exception is that in 2019, the observatory installed a new $CO_{2}$ analyzer that measures $CO_{2}$ concentration (defined as the number of $CO_{2}$ molecules out of a random million atmospheric molecules, or parts per million (ppm)) via cavity-ring down spectroscopy versus the previously used infrared absorption. We are presuming that this change in analysis technique does not dramatically alter the concentration of $CO_{2}$. Another exception is that this dataset has a gap in December 1975: for the purposes of these analyses, we decided to fill all gaps using the previous $CO_{2}$ concentration gathered (e.g. we decided to use the $CO_{2}$ concentration taken on November 11, 1975 as the $CO_{2}$ values for all of the missing December 1975 datapoints). A final note about this data set is that in November 29, 2022 Mauna Loa erupted and thus all subsequent data points were collected at the Maunakea observatories, approximately 21 miles north of the Mauna Loa observatory. For ease and data consistency, we have decided to only use data through the end of 2022 in our models and forecasts (up to but not inlcuding the recent Maunakea observations).

```{r Fetch data from NOAA, eval=F, echo=FALSE}
# change eval=T to run this for the first time, otherwise always load the (already saved) data
noaa_colnames <- c('year', 'month', 'day', 'decimal', 'ppm', 'n.days', 'lag.1Y', 'lag.10Y', 'delta.1800')
co2_present <- read_table('https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_weekly_mlo.txt', skip = 53, col_names = noaa_colnames, na="-999.99")
co2_present <- mutate(co2_present, date = as.Date(paste(year, month, day, sep="-"))) %>% mutate(week = yearweek(date, week_start=7)) # start week on Sunday
co2_present <- select(co2_present, -decimal, -delta.1800, -year, -month, -day)

# Create the tsibble
co2_present <- as_tsibble(co2_present, index=week)

# Save the data
save(co2_present, file='co2_data.RData')
```

```{r Load the data, eval=T, echo=FALSE}
load('co2_data.RData')
```

## Historical Trends in Atmospheric Carbon 

To begin, we conducted the same analysis on this dataset as was done in 1997, beginning with a map of the time series data, shown below in Figure 1, with a vertical red line at 1997 to reflect what new data we have compared to the previous report. 

```{r present time series, echo = FALSE}
ts_co2_present <- tsibble::as_tsibble(co2_present)

#time plot
p1_plot <- ggplot(ts_co2_present, aes(x = date, y = ppm)) +
  geom_line(color = 'steelblue') +
  geom_vline(xintercept = as.Date("1997-01-01"), color = "red") +
  labs(
    title = TeX(r'(Figure 1: Weekly Mean $CO_2$ at Mauna Loa 1974-2023)'),
    subtitle = "A continuation of the Keeling Curve (red line denotes 1997)",
    x = NULL,
    y = TeX(r'($CO_2$ parts per million)')
  ) + 
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") + 
	theme(axis.text.x=element_text(angle=90, vjust=0.5))
p1_plot
```
From this time series, we observe a steady continuation of the Keeling curve, with a continual increase in $CO_{2}$ concentration (ppm) as well as a notable seasonal component. The curve of the overall increasing $CO_{2}$ concentration, compared to data prior to 1997, does appear to be increasing at a slightly higher rate than what was previously observed.

To more carefully compare the distrbution and autocorrelation aspects of this times series, we conducted further analysis, as shown below in Figure 2.

```{r present histogram ACF PACF, echo = FALSE}
#histogram, ACF and PACF
p2_histogram <- ts_co2_present %>%
  ggplot(aes(x = ppm)) +
  geom_histogram() +
  labs(title = "Figure 2a", 
    subtitle=TeX(r'(Histogram of Weekly Mean $CO_2$)'),
        x = TeX(r'($CO_2$ parts per million)'))

p3_acf <- ts_co2_present %>%
  ACF(ppm) %>%
  autoplot() +
  labs(title = "Figure 2b", 
    subtitle=TeX(r'(ACF of Weekly Mean $CO_2$)'))

p4_pacf <- ts_co2_present %>%
  PACF(ppm) %>%
  autoplot() +
  labs(title = "Figure 2c", 
    subtitle=TeX(r'(PACF of Weekly Mean $CO_2$)'))

#arranging plots
(p2_histogram) /
  (p3_acf | p4_pacf)
```
Figure 2 reveals that the present dataset recapitulates the behavior observed in the 1997 dataset. Similar to what was seen in 1997, there is a strong autocorrelation in $CO_{2}$ concentration with very mild decay, maintaining its strong correlation even after a lag of 30 weeks (Fig 2b). The partial autocorrelation, PACF plot, reveals a first correlation of almost 1 and some cyclical correlations that may correspond to the seasonality of the data (Fib 2c). Taken together, this analysis suggests that there is a seasonal and potentially autoregressive component to the data.

# Models and Forecasts 

Through our exploratory data analysis, we found that our weekly data from 1974-2022 appears to behave very similarly to the data that was analyzed in 1997. Stemming from this analysis, we move to specifically evaluating the best linear and ARIMA model from the 1997 report against this newer dataset.

## Comparing 1997 Linear Models 

To begin, we compared the best linear model from the 1997 report. In that report, we assessed four different models and determined that the quadratic model with a seasonal adjustment component most accurately described the data up to 1997. To compare this model, we forecasted this model 25 years in the future to encompass 2023, and graphed it against our current dataset, shown below in Figure 3. 

```{r Load the fitted linear (quad) model, warning = FALSE, echo = FALSE}
load('1997_quad_seasonal_modelfit.RData') # loads a co2_quadratic_season var
```


```{r Compare against the realised values, echo=FALSE}
# 1. Forecast using the model until Dec 2022 (from 1997 = 25 years)
dec2022.forecast.quad.model <- fabletools::forecast(co2_quadratic_season, h="25 years")

# 2. Plot the forecast + realised values
dec2022.forecast.quad.model <- dec2022.forecast.quad.model %>% mutate(index.date = as.Date(index))
forecast.realised.plot <- ggplot() +
	geom_line(data=co2_present, aes(date, ppm, color="Realised")) +
	geom_line(data=dec2022.forecast.quad.model, aes(index.date, `.mean`, color="Forecast")) +
	scale_x_date(date_breaks="1 year", date_labels = "%Y") +
	scale_y_continuous(n.breaks=25) +
	theme(axis.text.x=element_text(angle=90, vjust=0.5)) +
	labs(title="Figure 3: Quadratic model forecast vs realised values 1997-2022", x=NULL, y="CO2 ppm") +
	scale_color_discrete(name = "Series")
forecast.realised.plot
```
Figure 3 reveals that the quadratic with seasonality model forecast fairly accurately predicts the actual data from 1997-2022. Up until about 2016, the 1997 model does seem to routinely over-predict the trough $CO_{2}$ values per yearand after 2016, the 1997 quadratic with seasonality model routinely under-predicts the peak $CO_{2}$ values per year. This suggests that while the quadratic model fits the data fairly closely, a model that combines several localized trends might better capture the data than a single overarching model.

## Comparing 1997 ARIMA Models 

```{r Load the ARIMA model}
co2_arima_fit <- readRDS('1997_arima_modelfit.rds')
```

```{r Compare against the realised values}
# 1. Forecast using the model until Dec 2022 (from 1997 = 25 years)
dec2022.forecast.arima.model <- fabletools::forecast(co2_arima_fit, h="25 years")

# 2. Plot the forecast + realised values
dec2022.forecast.arima.model <- dec2022.forecast.arima.model %>% mutate(index.date = as.Date(index))
arima.forecast.realised.plot <- ggplot() +
	geom_line(data=co2_present, aes(date, ppm, color="Realised")) +
	geom_line(data=dec2022.forecast.arima.model, aes(index.date, `.mean`, color="Forecast")) +
	scale_x_date(date_breaks="1 year", date_labels = "%Y") +
	theme(axis.text.x=element_text(angle=90, vjust=0.5)) +
	labs(title="ARIMA model forecast vs realised values 1997-2022", x=NULL, y="CO2 ppm") +
	scale_color_discrete(name = "Series")
arima.forecast.realised.plot
```

Descriptively compare realized atmospheric CO2 levels to those predicted by your forecast from the ARIMA model that you fitted in 1997 (i.e. "Task 3a"). Describe how the Keeling Curve evolved from 1997 to the present.

Sure we also fit some ARIMA models. And talk about them. 

## Evaluation of 1997 Forecasts 

In 1997 you made predictions about the first time that CO2 would cross 420 ppm. How close were your models to the truth?
After reflecting on your performance on this threshold-prediction task, continue to use the weekly data to generate a month-average series from 1997 to the present, and compare the overall forecasting performance of your models from Parts 2a and 3b over the entire period. (You should conduct formal tests for this task.)

```{r Produce the monthly series}
monthly.co2 <- co2_present %>%
	index_by(month = yearmonth(week)) %>%
	summarise(ppm = mean(ppm, na.rm=T)) %>%
	tidyr::fill(ppm, .direction = "down") %>%
	mutate(index.date = as.Date(month))
```

```{r Plot the monthly series against the forecast}
p1 <- ggplot() +
	geom_line(data=monthly.co2, aes(index.date, ppm, color="Realised")) +
	geom_line(data=dec2022.forecast.arima.model, aes(index.date, `.mean`, color="Forecast - ARIMA")) +
	geom_line(data=dec2022.forecast.quad.model, aes(index.date, `.mean`, color="Forecast - Quadratic")) +
	# geom_point(data=monthly.co2, aes(index.date, ppm, color="Realised")) +
	scale_x_date(date_breaks="1 year", date_labels = "%Y") +
	theme(axis.text.x=element_text(angle=90, vjust=0.5)) +
	labs(title="ARIMA model forecast vs quadratic model forecast vs realised values 1997-2022", x=NULL, y="CO2 ppm") +
	scale_color_discrete(name = "Series")
p1
```

```{r Change the names to match the forecast}
names(monthly.co2) <- c('index', 'value', 'index.date')
```


```{r Running the tests for comparison}
dec2022.forecast.arima.model %>% fabletools::accuracy(monthly.co2)
dec2022.forecast.quad.model %>% fabletools::accuracy(monthly.co2)
```


Because we have fitted a model, we can make predictions from that model. Our preferred model, named in \autoref{eq:one} is quite simple, and as you might notice, does not in fact match up with the model that we have fitted. However, from this model is is possible to reason about what the outcomes would be if the *input concept* were to be slightly ouside of the observed data range. In particular, if *input concept* were as high as $11$, then we would expect the *output concept* to be `r prediction_1[1,1]`, with a prediction interval that ranges from [`r prediction_1[1,2]`, `r prediction_1[1,3]`]

# Training New Models Based on Present Data

## (4 points) Task 5b: Train best models on present data
Seasonally adjust the weekly NOAA data, and split both seasonally-adjusted (SA) and non-seasonally-adjusted (NSA) series into training and test sets, using the last two years of observations as the test sets. For both SA and NSA series, fit ARIMA models using all appropriate steps. Measure and discuss how your models perform in-sample and (psuedo-) out-of-sample, comparing candidate models and explaining your choice. In addition, fit a polynomial time-trend model to the seasonally-adjusted series and compare its performance to that of your ARIMA model.

```{r Seasonally adjust data}
# There are missing values, so we have to fill in the blanks (fill with the previous week value)

co2_present <- co2_present %>% tidyr::fill(ppm, .direction = "down")
dcmp_add <- co2_present %>% model(stl=STL(ppm))
co2_present.components <- components(dcmp_add)
```

```{r Split train/test}
test.df <- filter(co2_present.components, year(week) >= 2020 & year(week) < 2023)
train.df <- filter(co2_present.components, year(week) < 2020)
```

```{r Seasonally adjusted data tests for stationarity}
train.diff.sa <- train.df %>% mutate(diff = tsibble::difference(season_adjust, lag=1))
PP.test(train.diff.sa$diff[-1])
adf.test(train.diff.sa$diff[-1], alternative = "stationary")
```

```{r Non-seasonally adjusted data tests for stationarity}
train.diff.nsa <- train.df %>% mutate(diff = tsibble::difference(ppm, lag=1))
PP.test(train.diff.nsa$diff[-1])
adf.test(train.diff.nsa$diff[-1], alternative = "stationary")
```

```{r ARIMA models}
train.df.ts <- select(train.df, week, ppm)
# autofit.arima.aic <- train.df.ts %>% model(auto=ARIMA(ppm ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="aic", stepwise=F, greedy=F))
# autofit.arima.bic <- train.df.ts %>% model(auto=ARIMA(ppm ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="bic", stepwise=F, greedy=F))
autofit.arima.aic <- readRDS('autofit.arima.aic.nsa.rds')
autofit.arima.bic <- readRDS('autofit.arima.bic.nsa.rds')
autofit.arima.aic %>% report()
autofit.arima.bic %>% report()

train.df.ts.sa <- select(train.df, week, season_adjust)
# autofit.arima.aic.sa <- train.df.ts.sa %>% model(auto=ARIMA(season_adjust ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="aic", stepwise=F, greedy=F))
# autofit.arima.bic.sa <- train.df.ts.sa %>% model(auto=ARIMA(season_adjust ~ 1 + pdq(0:10,0:2,0:10) + PDQ(0:10,0:2,0:10), ic="bic", stepwise=F, greedy=F))
# saveRDS(autofit.arima.aic.sa, file="autofit.arima.aic.sa.Rds")
# saveRDS(autofit.arima.bic.sa, file="autofit.arima.bic.sa.Rds")

autofit.arima.aic.sa <- readRDS('autofit.arima.aic.sa.Rds')
autofit.arima.bic.sa <- readRDS('autofit.arima.bic.sa.Rds')

autofit.arima.aic.sa %>% report()
autofit.arima.bic.sa %>% report()
```

### Evaluating accuracy


```{r In-sample}
bind_cols(data.frame(
	model=c('ARIMA(1,0,4)(1,1,0)[52] (NSA data)', 'ARIMA(0,1,2)(1,0,0)[52] (SA data)', 'ARIMA(1,0,2)(1,1,0)[52] (NSA data)', 'ARIMA(0,1,2)(1,0,0)[52] (SA data)'),
	IC=c('AIC', 'AIC', 'BIC', 'BIC')
	),
bind_rows(
	fabletools::accuracy(autofit.arima.aic),
	fabletools::accuracy(autofit.arima.aic.sa),
	fabletools::accuracy(autofit.arima.bic),
	fabletools::accuracy(autofit.arima.bic.sa),
))
```


```{r Out of sample NSA}
# Using the ARIMA(1,0,2)(1,1,0) (chosen by AIC)
nsa.fc <- fabletools::forecast(autofit.arima.bic,h="2 years")
attr(autofit.arima.bic$auto[[1]]$fit$tsp$range, 'week_start') <- 7
nd <- tsibble(week=yearweek(seq(ymd('2019-12-29'), ymd('2023-01-01'), by ='1 week'), week_start = 7))
nd <- tsibble::fill_gaps(nd)
attr(nd$week, "week_start") <- 7
nd <- as_tsibble(nd)
# nsa.fc <- fabletools::forecast(autofit.arima.bic, new_data=nd)
nsa.fc <- fabletools::forecast(autofit.arima.bic, h="2 years")
nsa.fc %>% fabletools::accuracy(select(test.df, week, ppm))
```

```{r Out of sample SA}
```

# How Bad Could It Get?

## (3 points) Task Part 6b: How bad could it get?
With the non-seasonally adjusted data series, generate predictions for when atmospheric CO2 is expected to be at 420 ppm and 500 ppm levels for the first and final times (consider prediction intervals as well as point estimates in your answer). Generate a prediction for atmospheric CO2 levels in the year 2122. How confident are you that these will be accurate predictions?

# Conclusions 

What to conclude is unclear. 


